# Neural Network Implementation for Income Prediction

Neural network implementation for income prediction (>$50K) using Adult Census dataset. Features data preprocessing, hyperparameter optimization, regularization techniques, and baseline comparison with logistic regression. Built with PyTorch.

## ğŸ‘¥ Autores
- **Samuel SuÃ¡rez**
- **Jade Manon Nicolas**

**Curso**: Inteligencia Artificial Aplicada a la EconomÃ­a - Parcial 2

## ğŸ“– DescripciÃ³n del Proyecto

Este proyecto desarrolla modelos de machine learning para predecir si una persona gana mÃ¡s de $50,000 anuales basÃ¡ndose en caracterÃ­sticas demogrÃ¡ficas y socioeconÃ³micas del dataset Adult Census Income del repositorio UCI Machine Learning.

### ğŸ¯ Objetivos Principales
- Implementar una red neuronal (MLP) para clasificaciÃ³n binaria de ingresos
- Comparar rendimiento entre modelo baseline (regresiÃ³n logÃ­stica) y redes neuronales
- Aplicar tÃ©cnicas de regularizaciÃ³n: Dropout y Early Stopping
- Realizar experimentaciÃ³n sistemÃ¡tica con hiperparÃ¡metros
- Evaluar y prevenir overfitting/underfitting

## ğŸ“Š Dataset

**Fuente**: [UCI Adult Census Income Dataset](https://archive.ics.uci.edu/dataset/2/adult)

- **AÃ±o**: 1994 (Censo estadounidense)
- **Registros de entrenamiento**: 32,561
- **Registros de prueba**: 16,281
- **CaracterÃ­sticas**: 14 variables predictoras
- **Variable objetivo**: Binaria (â‰¤50K / >50K)

### Variables del Dataset
| Tipo | Variables |
|------|-----------|
| **DemogrÃ¡ficas** | age, sex, race, native-country |
| **Educativas** | education, education-num |
| **Laborales** | workclass, occupation, hours-per-week |
| **Financieras** | capital-gain, capital-loss |
| **Familiares** | marital-status, relationship |

## ğŸ”¬ MetodologÃ­a

### 1. AnÃ¡lisis Exploratorio de Datos (EDA)
- AnÃ¡lisis de distribuciones y valores faltantes
- IdentificaciÃ³n de desbalances de clase
- DetecciÃ³n de variables correlacionadas

### 2. Procesamiento de Datos

#### Manejo de Valores Faltantes
- **Porcentaje**: Solo 0.92% de valores faltantes
- **Variables afectadas**: workclass, occupation, native-country
- **Estrategia**: ImputaciÃ³n por moda (valor mÃ¡s frecuente)
- **PrevenciÃ³n de data leakage**: Uso de estadÃ­sticas del conjunto de entrenamiento

#### Transformaciones de Variables
| TransformaciÃ³n | JustificaciÃ³n |
|----------------|---------------|
| `capital-gain` + `capital-loss` â†’ `capital-net` | Reducir sparsity y combinar informaciÃ³n relacionada |
| `native-country` â†’ `US/Non-US` | Prevenir overfitting por categorÃ­as con pocas muestras |
| One-hot encoding | Manejo apropiado de variables categÃ³ricas |
| EstandarizaciÃ³n | NormalizaciÃ³n de variables continuas |

### 3. Arquitecturas Implementadas

#### Modelo Baseline
- **Algoritmo**: RegresiÃ³n LogÃ­stica
- **PropÃ³sito**: Establecer lÃ­nea base de comparaciÃ³n

#### Red Neuronal (MLP)
- **Framework**: PyTorch
- **Arquitectura**: Multilayer Perceptron
- **FunciÃ³n de pÃ©rdida**: Binary Cross Entropy
- **Optimizador**: Adam

## ğŸ§ª ExperimentaciÃ³n

### Experimentos sin RegularizaciÃ³n (5 configuraciones)

| Experimento | Variable | Configuraciones Probadas |
|-------------|----------|-------------------------|
| 1 | Neuronas por capa | 128, 256, 512 |
| 2 | NÃºmero de capas | 3, 6, 12 |
| 3 | Batch size | 512, 1024, 2048 |
| 4 | Learning rate | 0.0005, 0.001, 0.002 |
| 5 | FunciÃ³n activaciÃ³n | ReLU, LeakyReLU, ELU |

**Mejor configuraciÃ³n sin regularizaciÃ³n**:
- 3 capas ocultas, 128 neuronas por capa
- Batch size: 2048, Learning rate: 0.0005
- FunciÃ³n de activaciÃ³n: ELU

### Experimentos con RegularizaciÃ³n

#### TÃ©cnicas Implementadas
- **Dropout**: PrevenciÃ³n de overfitting durante entrenamiento
- **Early Stopping**: DetenciÃ³n automÃ¡tica basada en pÃ©rdida de validaciÃ³n

**ConfiguraciÃ³n final optimizada**:
- **Capas**: 8 capas ocultas
- **Neuronas por capa**: 256
- **Batch size**: 1024
- **Learning rate**: 0.001
- **ActivaciÃ³n**: ELU
- **RegularizaciÃ³n**: Dropout + Early Stopping

## ğŸ“ˆ Resultados

### MÃ©tricas de EvaluaciÃ³n
- **Accuracy**: PrecisiÃ³n general del modelo
- **Precision**: Exactitud en predicciones positivas
- **Recall**: Capacidad de detectar casos positivos
- **F1-Score**: Media armÃ³nica de precision y recall
- **AUC-ROC**: Ãrea bajo la curva ROC


*Nota: MÃ©tricas completas disponibles en el notebook y en el reporte de trabajo*

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Python 3.x**
- **PyTorch**: ImplementaciÃ³n de redes neuronales
- **Pandas**: ManipulaciÃ³n de datos
- **NumPy**: Operaciones numÃ©ricas
- **Scikit-learn**: MÃ©tricas y modelo baseline
- **Matplotlib/Seaborn**: VisualizaciÃ³n
- **Google Colab**: Entorno de desarrollo

## ğŸ“ Estructura del Repositorio

```
â”œâ”€â”€ README.md
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ Income_Prediction_Neural_Networks.ipynb
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ Reporte_Parcial_2_HE2-2.pdf
â”‚   â””â”€â”€ HE2_Inteligencia_Artificial_Aplicada.pdf
â”œâ”€â”€ data/
    â”œâ”€â”€ adult.data
    â””â”€â”€ adult.test

```

## ğŸš€ Instrucciones de Uso

### 1. Clonar el repositorio
```bash
git clone https://github.com/SamuelSuaV/income-prediction-neural-networks.git
cd income-prediction-neural-networks
```

### 2. Descargar datos
Descargar repositorio y subir a Google Drive.

### 3. Ejecutar notebook
```bash
jupyter notebook notebook/Income_Prediction_Neural_Networks.ipynb
```
Debe ejecutarse desde Drive.

## ğŸ” Hallazgos Clave

### Procesamiento de Datos
- La combinaciÃ³n de variables financieras (`capital-net`) mejora la representaciÃ³n
- La simplificaciÃ³n geogrÃ¡fica previene overfitting
- La imputaciÃ³n por moda es efectiva con pocos valores faltantes

### Arquitectura de Red
- **ELU** supera a ReLU y LeakyReLU evitando "muerte de neuronas"
- Redes mÃ¡s profundas (8 capas) mejoran el log-loss sin sacrificar F1-score significativamente
- El equilibrio entre batch size y learning rate es crucial

### RegularizaciÃ³n
- **Early Stopping** previene efectivamente el overfitting
- **Dropout** mejora la generalizaciÃ³n
- La regularizaciÃ³n permite arquitecturas mÃ¡s complejas sin degradaciÃ³n

## ğŸ“Š Visualizaciones Incluidas

- Distribuciones de variables categÃ³ricas y continuas
- Curvas de pÃ©rdida: entrenamiento vs validaciÃ³n
- AnÃ¡lisis de overfitting/underfitting por experimento
- ComparaciÃ³n de funciones de activaciÃ³n

## ğŸ“š Referencias

- GÃ©ron, A. (2019). *Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow: Concepts, tools, and techniques to build intelligent systems* (2nd ed.). O'Reilly.
- UCI Machine Learning Repository: Adult Data Set


---

**Nota**: Este notebook debe ejecutarse de inicio a fin para reproducir los resultados reportados. Cualquier error en la ejecuciÃ³n puede afectar la reproducibilidad de los resultados.
