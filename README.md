# Neural Network Implementation for Income Prediction

Neural network implementation for income prediction (>$50K) using Adult Census dataset. Features data preprocessing, hyperparameter optimization, regularization techniques, and baseline comparison with logistic regression. Built with PyTorch.

## üë• Autores
- **Samuel Su√°rez**
- **Jade Manon Nicolas**

**Curso**: Inteligencia Artificial Aplicada a la Econom√≠a - Parcial 2

## üìñ Descripci√≥n del Proyecto

Este proyecto desarrolla modelos de machine learning para predecir si una persona gana m√°s de $50,000 anuales bas√°ndose en caracter√≠sticas demogr√°ficas y socioecon√≥micas del dataset Adult Census Income del repositorio UCI Machine Learning.

### üéØ Objetivos Principales
- Implementar una red neuronal (MLP) para clasificaci√≥n binaria de ingresos
- Comparar rendimiento entre modelo baseline (regresi√≥n log√≠stica) y redes neuronales
- Aplicar t√©cnicas de regularizaci√≥n: Dropout y Early Stopping
- Realizar experimentaci√≥n sistem√°tica con hiperpar√°metros
- Evaluar y prevenir overfitting/underfitting

## üìä Dataset

**Fuente**: [UCI Adult Census Income Dataset](https://archive.ics.uci.edu/dataset/2/adult)

- **A√±o**: 1994 (Censo estadounidense)
- **Registros de entrenamiento**: 32,561
- **Registros de prueba**: 16,281
- **Caracter√≠sticas**: 14 variables predictoras
- **Variable objetivo**: Binaria (‚â§50K / >50K)

### Variables del Dataset
| Tipo | Variables |
|------|-----------|
| **Demogr√°ficas** | age, sex, race, native-country |
| **Educativas** | education, education-num |
| **Laborales** | workclass, occupation, hours-per-week |
| **Financieras** | capital-gain, capital-loss |
| **Familiares** | marital-status, relationship |

## üî¨ Metodolog√≠a

### 1. An√°lisis Exploratorio de Datos (EDA)
- An√°lisis de distribuciones y valores faltantes
- Identificaci√≥n de desbalances de clase
- Detecci√≥n de variables correlacionadas

### 2. Procesamiento de Datos

#### Manejo de Valores Faltantes
- **Porcentaje**: Solo 0.92% de valores faltantes
- **Variables afectadas**: workclass, occupation, native-country
- **Estrategia**: Imputaci√≥n por moda (valor m√°s frecuente)
- **Prevenci√≥n de data leakage**: Uso de estad√≠sticas del conjunto de entrenamiento

#### Transformaciones de Variables
| Transformaci√≥n | Justificaci√≥n |
|----------------|---------------|
| `capital-gain` + `capital-loss` ‚Üí `capital-net` | Reducir sparsity y combinar informaci√≥n relacionada |
| `native-country` ‚Üí `US/Non-US` | Prevenir overfitting por categor√≠as con pocas muestras |
| One-hot encoding | Manejo apropiado de variables categ√≥ricas |
| Estandarizaci√≥n | Normalizaci√≥n de variables continuas |

### 3. Arquitecturas Implementadas

#### Modelo Baseline
- **Algoritmo**: Regresi√≥n Log√≠stica
- **Prop√≥sito**: Establecer l√≠nea base de comparaci√≥n

#### Red Neuronal (MLP)
- **Framework**: PyTorch
- **Arquitectura**: Multilayer Perceptron
- **Funci√≥n de p√©rdida**: Binary Cross Entropy
- **Optimizador**: Adam

## üß™ Experimentaci√≥n

### Experimentos sin Regularizaci√≥n (5 configuraciones)

| Experimento | Variable | Configuraciones Probadas |
|-------------|----------|-------------------------|
| 1 | Neuronas por capa | 128, 256, 512 |
| 2 | N√∫mero de capas | 3, 6, 12 |
| 3 | Batch size | 512, 1024, 2048 |
| 4 | Learning rate | 0.0005, 0.001, 0.002 |
| 5 | Funci√≥n activaci√≥n | ReLU, LeakyReLU, ELU |

**Mejor configuraci√≥n sin regularizaci√≥n**:
- 3 capas ocultas, 128 neuronas por capa
- Batch size: 2048, Learning rate: 0.0005
- Funci√≥n de activaci√≥n: ELU

### Experimentos con Regularizaci√≥n

#### T√©cnicas Implementadas
- **Dropout**: Prevenci√≥n de overfitting durante entrenamiento
- **Early Stopping**: Detenci√≥n autom√°tica basada en p√©rdida de validaci√≥n

**Configuraci√≥n final optimizada**:
- **Capas**: 8 capas ocultas
- **Neuronas por capa**: 256
- **Batch size**: 1024
- **Learning rate**: 0.001
- **Activaci√≥n**: ELU
- **Regularizaci√≥n**: Dropout + Early Stopping

## üìà Resultados

### M√©tricas de Evaluaci√≥n
- **Accuracy**: Precisi√≥n general del modelo
- **Precision**: Exactitud en predicciones positivas
- **Recall**: Capacidad de detectar casos positivos
- **F1-Score**: Media arm√≥nica de precision y recall
- **AUC-ROC**: √Årea bajo la curva ROC


*Nota: M√©tricas completas disponibles en el notebook y en el reporte de trabajo*

## üõ†Ô∏è Tecnolog√≠as Utilizadas

- **Python 3.x**
- **PyTorch**: Implementaci√≥n de redes neuronales
- **Pandas**: Manipulaci√≥n de datos
- **NumPy**: Operaciones num√©ricas
- **Scikit-learn**: M√©tricas y modelo baseline
- **Matplotlib/Seaborn**: Visualizaci√≥n
- **Google Colab**: Entorno de desarrollo

## üìÅ Estructura del Repositorio

```
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ notebook/
‚îÇ   ‚îî‚îÄ‚îÄ Income_Prediction_Neural_Networks.ipynb
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ Reporte_Parcial_2_HE2-2.pdf
‚îÇ   ‚îî‚îÄ‚îÄ HE2_Inteligencia_Artificial_Aplicada.pdf
‚îú‚îÄ‚îÄ data/
    ‚îú‚îÄ‚îÄ adult.data
    ‚îî‚îÄ‚îÄ adult.test

```

## üöÄ Instrucciones de Uso

### 1. Clonar el repositorio
```bash
git clone https://github.com/SamuelSuaV/income-prediction-neural-networks.git
cd income-prediction-neural-networks
```

### 2. Descargar datos
Descargar repositorio y subir a Google Drive.

### 3. Ejecutar notebook
```bash
jupyter notebook notebook/Income_Prediction_Neural_Networks.ipynb
```
Debe ejecutarse desde Drive.

### 4. Permitir acceso a Drive
El repositorio debe colocarse en la secci√≥n de "Mis Archivos de OneDrive". Cuando se corra el notebook, se debe permitir el acceso.

## üîç Hallazgos Clave

### Procesamiento de Datos
- La combinaci√≥n de variables financieras (`capital-net`) mejora la representaci√≥n
- La simplificaci√≥n geogr√°fica previene overfitting
- La imputaci√≥n por moda es efectiva con pocos valores faltantes

### Arquitectura de Red
- **ELU** supera a ReLU y LeakyReLU evitando "muerte de neuronas"
- Redes m√°s profundas (8 capas) mejoran el log-loss sin sacrificar F1-score significativamente
- El equilibrio entre batch size y learning rate es crucial

### Regularizaci√≥n
- **Early Stopping** previene efectivamente el overfitting
- **Dropout** mejora la generalizaci√≥n
- La regularizaci√≥n permite arquitecturas m√°s complejas sin degradaci√≥n

## üìä Visualizaciones Incluidas

- Distribuciones de variables categ√≥ricas y continuas
- Curvas de p√©rdida: entrenamiento vs validaci√≥n
- An√°lisis de overfitting/underfitting por experimento
- Comparaci√≥n de funciones de activaci√≥n

## üìö Referencias

- G√©ron, A. (2019). *Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow: Concepts, tools, and techniques to build intelligent systems* (2nd ed.). O'Reilly.
- UCI Machine Learning Repository: Adult Data Set


---

**Nota**: Este notebook debe ejecutarse de inicio a fin para reproducir los resultados reportados. Cualquier error en la ejecuci√≥n puede afectar la reproducibilidad de los resultados.
